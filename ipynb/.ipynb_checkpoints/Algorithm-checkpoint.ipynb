{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import py_pcha\n",
    "#from py_pcha import PCHA\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.matlib import repmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/ArchetypalAnalysis/data/us_states_covid19_daily.csv\")\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/Users/u0984549/Documents/GitHub/ArchetypalAnalysis/data/us_states_covid19_daily.csv\")\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time = data[['date','state','positive','negative','totalTestResults','recovered', 'death']]\n",
    "data_time = data_time.dropna()\n",
    "data_time = data_time.reset_index()\n",
    "data_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time['state'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['CO', 'UT', 'ND', 'NY', 'NC', 'AR', 'MS', 'CT', 'IN']\n",
    "data_time_sm = data_time.loc[data_time['state'].isin(states)]\n",
    "data_time_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# you could also import date instead of datetime and use that.\n",
    "#date = datetime(year=int(s[0:4]), month=int(s[4:6]), day=int(s[6:8]))\n",
    "\n",
    "for i in range(len(data_time_sm)):\n",
    "    string_date = data_time[\"date\"][i]\n",
    "    string_date = str(string_date)\n",
    "    data_time[\"date\"][i] = datetime(year=int(string_date[0:4]), \n",
    "                                    month=int(string_date[4:6]),\n",
    "                                   day=int(string_date[6:8]))\n",
    "    data_time[\"date\"][i] = data_time[\"date\"][i].date()\n",
    "    \n",
    "data_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# you could also import date instead of datetime and use that.\n",
    "#date = datetime(year=int(s[0:4]), month=int(s[4:6]), day=int(s[6:8]))\n",
    "\n",
    "for i in range(len(data_time)):\n",
    "    string_date = data_time[\"date\"][i]\n",
    "    string_date = str(string_date)\n",
    "    data_time[\"date\"][i] = datetime(year=int(string_date[0:4]), \n",
    "                                    month=int(string_date[4:6]),\n",
    "                                   day=int(string_date[6:8]))\n",
    "    data_time[\"date\"][i] = data_time[\"date\"][i].date()\n",
    "    \n",
    "data_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time.to_csv('/Users/u0984549/Documents/GitHub/ArchetypalAnalysis/data/COVID19time.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time.to_csv('/Users/markomiholjcic/Documents/GitHub/ArchetypalAnalysis/data/COVID19time.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for 50 states, DC, and 5 territories on December 6, 2020. Select states and territories with missing values were removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec6 = data.loc[data['date'] == 20201206]\n",
    "dec6 = dec6[['state','positive','negative','totalTestResults','recovered', 'death']]\n",
    "dec6 = dec6.dropna()\n",
    "dec6_state = dec6[['state']]\n",
    "\n",
    "dec6raw = dec6\n",
    "\n",
    "dec6 = dec6[['positive','negative','totalTestResults','recovered', 'death']]\n",
    "dec6 = dec6.T\n",
    "#dec6_state\n",
    "dec6_variables = pd.DataFrame([dec6.index]).T\n",
    "#dec6raw\n",
    "dec6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec6raw.to_csv('/Users/markomiholjcic/Documents/GitHub/ArchetypalAnalysis/data/COVID19states.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec6b = data.loc[data['date'] == 20201206]\n",
    "dec6b = dec6b[['positive','negative','totalTestResults','recovered', 'death', \n",
    "              'probableCases','hospitalizedCurrently',\n",
    "             'negativeRegularScore','positiveScore','deathIncrease',\n",
    "              'totalTestsAntibody','dataQualityGrade', 'deathProbable']]\n",
    "dec6b = dec6b.dropna()\n",
    "dec6b = dec6b[:4]\n",
    "dec6b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec6.to_csv('/Users/markomiholjcic/Documents/GitHub/ArchetypalAnalysis/data/COVID19.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec6b.to_csv('/Users/markomiholjcic/Documents/GitHub/ArchetypalAnalysis/data/COVID19BIG.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec6.to_csv('/Users/u0984549/Documents/GitHub/ArchetypalAnalysis/data/COVID19.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dec6_wo_st = dec6[['positive','negative','totalTestResults','recovered', 'death']]\n",
    "dec6_wo_st = dec6.to_numpy()\n",
    "dec6_wo_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC, S, C, SSE, varexpl = PCHA(dec6_wo_st, noc=3, I = None, delta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def furthest_sum(K, noc, i, exclude=[]):\n",
    "    \n",
    "    def max_ind_val(l):\n",
    "        return max(zip(range(len(l)), l), key=lambda x: x[1])\n",
    "    \n",
    "    I, J = K.shape\n",
    "    #print(I,J)\n",
    "    index = np.array(range(J))\n",
    "    index[exclude] = 0\n",
    "    index[i] = -1\n",
    "    ind_t = i\n",
    "    sum_dist = np.zeros((1, J), np.complex128)\n",
    "\n",
    "    if J > noc * I:\n",
    "        Kt = K\n",
    "        Kt2 = np.sum(Kt**2, axis=0)\n",
    "        for k in range(1, noc + 11):\n",
    "            if k > noc - 1:\n",
    "                Kq = np.dot(Kt[:, i[0]], Kt)\n",
    "                #Kt_shape = Kt.shape\n",
    "                #Kts = Kt[:, i[0]]\n",
    "                #Ktsp = Kts.shape\n",
    "                #Kq_shape = Kq.shape\n",
    "                #print(Kt_shape,Ktsp,Kq_shape)\n",
    "                sum_dist -= np.lib.scimath.sqrt(Kt2 - 2 * Kq + Kt2[i[0]])\n",
    "                index[i[0]] = i[0]\n",
    "                i = i[1:]\n",
    "            t = np.where(index != -1)[0]\n",
    "            Kq = np.dot(Kt[:, ind_t].T, Kt)\n",
    "            sum_dist += np.lib.scimath.sqrt(Kt2 - 2 * Kq + Kt2[ind_t])\n",
    "            #print(Kt2)\n",
    "            ind, val = max_ind_val(sum_dist[:, t][0].real)\n",
    "            ind_t = t[ind]\n",
    "            i.append(ind_t)\n",
    "            index[ind_t] = -1\n",
    "    else:\n",
    "        if I != J or np.sum(K - K.T) != 0:  # Generate kernel if K not one\n",
    "            Kt = K\n",
    "            K = np.dot(Kt.T, Kt)\n",
    "            K = np.lib.scimath.sqrt(\n",
    "                repmat(np.diag(K), J, 1) - 2 * K + \\\n",
    "                repmat(np.mat(np.diag(K)).T, 1, J)\n",
    "            )\n",
    "\n",
    "        Kt2 = np.diag(K)  # Horizontal\n",
    "        for k in range(1, noc + 11):\n",
    "            if k > noc - 1:\n",
    "                sum_dist -= np.lib.scimath.sqrt(Kt2 - 2 * K[i[0], :] + Kt2[i[0]])\n",
    "                index[i[0]] = i[0]\n",
    "                i = i[1:]\n",
    "            t = np.where(index != -1)[0]\n",
    "            sum_dist += np.lib.scimath.sqrt(Kt2 - 2 * K[ind_t, :] + Kt2[ind_t])\n",
    "            ind, val = max_ind_val(sum_dist[:, t][0].real)\n",
    "            ind_t = t[ind]\n",
    "            i.append(ind_t)\n",
    "            index[ind_t] = -1\n",
    "\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Principal Convex Hull Analysis (PCHA) / Archetypal Analysis.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "\n",
    "#from py_pcha.furthest_sum import furthest_sum\n",
    "\n",
    "\n",
    "def PCHAm(X, noc, I=None, U=None, delta=0, verbose=False, conv_crit=1E-6, maxiter=500):\n",
    "    \"\"\"Return archetypes of dataset.\n",
    "    Note: Commonly data is formatted to have shape (examples, dimensions).\n",
    "    This function takes input and returns output of the transposed shape,\n",
    "    (dimensions, examples).\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy.2darray\n",
    "        Data matrix in which to find archetypes\n",
    "    noc : int\n",
    "        Number of archetypes to find\n",
    "    I : 1d-array\n",
    "        Entries of X to use for dictionary in C (optional)\n",
    "    U : 1d-array\n",
    "        Entries of X to model in S (optional)\n",
    "    Output\n",
    "    ------\n",
    "    XC : numpy.2darray\n",
    "        I x noc feature matrix (i.e. XC=X[:,I]*C forming the archetypes)\n",
    "    S : numpy.2darray\n",
    "        noc x length(U) matrix, S>=0 |S_j|_1=1\n",
    "    C : numpy.2darray\n",
    "        noc x length(U) matrix, S>=0 |S_j|_1=1\n",
    "    SSE : float\n",
    "        Sum of Squared Errors\n",
    "    varexlp : float\n",
    "        Percent variation explained by the model\n",
    "    \"\"\"\n",
    "    def S_update(S, XCtX, CtXtXC, muS, SST, SSE, niter):\n",
    "        \"\"\"Update S for one iteration of the algorithm.\"\"\"\n",
    "        noc, J = S.shape\n",
    "        e = np.ones((noc, 1))\n",
    "        #print(e.ndim)\n",
    "        for k in range(niter):\n",
    "            SSE_old = SSE\n",
    "            #print(SSE_old)\n",
    "            g = (np.dot(CtXtXC, S) - XCtX) / (SST / J)\n",
    "            #print(g)\n",
    "            g = g - e * np.sum(g.A * S.A, axis=0)\n",
    "            #print(g)\n",
    "\n",
    "            S_old = S\n",
    "            #print(S_old)\n",
    "            while True:\n",
    "                S = (S_old - g * muS).clip(min=0)\n",
    "                S = S / np.dot(e, np.sum(S, axis=0))\n",
    "                #print(S)\n",
    "                SSt = S * S.T\n",
    "                #print(SSt)\n",
    "                SSE = SST - 2 * np.sum(XCtX.A * S.A) + np.sum(CtXtXC.A * SSt.A)\n",
    "                #print(SSE)\n",
    "                #print(SSE_old)\n",
    "                if SSE <= SSE_old * (1 + 1e-9):\n",
    "                    muS = muS * 1.2\n",
    "                    #print(muS)\n",
    "                    break\n",
    "                else:\n",
    "                    muS = muS / 2\n",
    "\n",
    "        return S, SSE, muS, SSt\n",
    "\n",
    "    def C_update(X, XSt, XC, SSt, C, delta, muC, mualpha, SST, SSE, niter=1):\n",
    "        \"\"\"Update C for one iteration of the algorithm.\"\"\"\n",
    "        J, nos = C.shape\n",
    "\n",
    "        if delta != 0:\n",
    "            alphaC = np.sum(C, axis=0).A[0]\n",
    "            C = np.dot(C, np.diag(1 / alphaC))\n",
    "\n",
    "        #print(C)\n",
    "        e = np.ones((J, 1))\n",
    "        XtXSt = np.dot(X.T, XSt)\n",
    "        #print(XtXSt)\n",
    "\n",
    "        for k in range(niter):\n",
    "\n",
    "            # Update C\n",
    "            SSE_old = SSE\n",
    "            #print(SSE_old)\n",
    "            g = (np.dot(X.T, np.dot(XC, SSt)) - XtXSt) / SST\n",
    "            #print(g)\n",
    "\n",
    "            if delta != 0:\n",
    "                g = np.dot(g, np.diag(alphaC))\n",
    "            g = g.A - e * np.sum(g.A * C.A, axis=0)\n",
    "            #print(g)\n",
    "            \n",
    "            C_old = C\n",
    "            while True:\n",
    "                C = (C_old - muC * g).clip(min=0)\n",
    "                #print(C)\n",
    "                nC = np.sum(C, axis=0) + np.finfo(float).eps\n",
    "                C = np.dot(C, np.diag(1 / nC.A[0]))\n",
    "                #print(C)\n",
    "                \n",
    "                if delta != 0:\n",
    "                    Ct = C * np.diag(alphaC)\n",
    "                else:\n",
    "                    Ct = C\n",
    "\n",
    "                XC = np.dot(X, Ct)\n",
    "                CtXtXC = np.dot(XC.T, XC)\n",
    "                #print(CtXtXC)\n",
    "                SSE = SST - 2 * np.sum(XC.A * XSt.A) + np.sum(CtXtXC.A * SSt.A)\n",
    "                #print(SSE)\n",
    "                \n",
    "                if SSE <= SSE_old * (1 + 1e-9):\n",
    "                    muC = muC * 1.2\n",
    "                    break\n",
    "                else:\n",
    "                    muC = muC / 2\n",
    "\n",
    "            # Update alphaC\n",
    "            SSE_old = SSE\n",
    "            if delta != 0:\n",
    "                g = (np.diag(CtXtXC * SSt).T / alphaC - np.sum(C.A * XtXSt.A)) / (SST * J)\n",
    "                #print(g)\n",
    "                alphaC_old = alphaC\n",
    "                while True:\n",
    "                    alphaC = alphaC_old - mualpha * g\n",
    "                    alphaC[alphaC < 1 - delta] = 1 - delta\n",
    "                    alphaC[alphaC > 1 + delta] = 1 + delta\n",
    "\n",
    "                    XCt = np.dot(XC, np.diag(alphaC / alphaC_old))\n",
    "                    CtXtXC = np.dot(XCt.T, XCt)\n",
    "                    SSE = SST - 2 * np.sum(XCt.A * XSt.A) + np.sum(CtXtXC.A * SSt.A)\n",
    "                    #print(SSE)\n",
    "                    \n",
    "                    if SSE <= SSE_old * (1 + 1e-9):\n",
    "                        mualpha = mualpha * 1.2\n",
    "                        XC = XCt\n",
    "                        break\n",
    "                    else:\n",
    "                        mualpha = mualpha / 2\n",
    "\n",
    "        if delta != 0:\n",
    "            C = C * np.diag(alphaC)\n",
    "\n",
    "        return C, SSE, muC, mualpha, CtXtXC, XC\n",
    "\n",
    "    N, M = X.shape\n",
    "    \n",
    "\n",
    "    if I is None:\n",
    "        I = range(M)\n",
    "    if U is None:\n",
    "        U = range(M)\n",
    "        \n",
    "    #print(X[:,U])\n",
    "\n",
    "    SST = np.sum(X[:, U] * X[:, U])\n",
    "    #print(SST)\n",
    "    \n",
    "    #print(X[:,I])\n",
    "\n",
    "    #Initialize C\n",
    "    try:\n",
    "       i = furthest_sum(X[:, I], noc, [int(np.ceil(len(I) * np.random.rand()))])\n",
    "    except IndexError:\n",
    "        class InitializationException(Exception): pass\n",
    "        raise InitializationException(\"Initialization does not converge. Too few examples in dataset.\")\n",
    "\n",
    "    #i = [1,2,0]\n",
    "        \n",
    "    j = range(noc)\n",
    "    C = csr_matrix((np.ones(len(i)), (i, j)), shape=(len(I), noc)).todense()\n",
    "    #print(C)\n",
    "    \n",
    "    XC = np.dot(X[:, I], C)\n",
    "    #print(XC)\n",
    "\n",
    "    muS, muC, mualpha = 1, 1, 1\n",
    "\n",
    "    # Initialise S\n",
    "    XCtX = np.dot(XC.T, X[:, U])\n",
    "    #print(XCtX)\n",
    "    CtXtXC = np.dot(XC.T, XC)\n",
    "    #print(CtXtXC)\n",
    "    S = -np.log(np.random.random((noc, len(U))))\n",
    "    #S = -np.log((np.ones((3,48))-0.5))\n",
    "    #print(S)\n",
    "    S = S / np.dot(np.ones((noc, 1)), np.mat(np.sum(S, axis=0)))\n",
    "    #print(S)\n",
    "    SSt = np.dot(S, S.T)\n",
    "    SSE = SST - 2 * np.sum(XCtX.A * S.A) + np.sum(CtXtXC.A * SSt.A)\n",
    "    #print(SSE)\n",
    "    S, SSE, muS, SSt = S_update(S, XCtX, CtXtXC, muS, SST, SSE, 25)\n",
    "    #print(S, SSE, muS, SSt)\n",
    "\n",
    "    # Set PCHA parameters\n",
    "    iter_ = 0\n",
    "    dSSE = np.inf\n",
    "    t1 = dt.now()\n",
    "    varexpl = (SST - SSE) / SST\n",
    "    #print(varexpl)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\nPrincipal Convex Hull Analysis / Archetypal Analysis')\n",
    "        print('A ' + str(noc) + ' component model will be fitted')\n",
    "        print('To stop algorithm press control C\\n')\n",
    "\n",
    "    dheader = '%10s | %10s | %10s | %10s | %10s | %10s | %10s | %10s' % ('Iteration', 'Expl. var.', 'Cost func.', 'Delta SSEf.', 'muC', 'mualpha', 'muS', ' Time(s)   ')\n",
    "    dline = '-----------+------------+------------+-------------+------------+------------+------------+------------+'\n",
    "\n",
    "    while np.abs(dSSE) >= conv_crit * np.abs(SSE) and iter_ < maxiter and varexpl < 0.9999:\n",
    "        if verbose and iter_ % 100 == 0:\n",
    "            print(dline)\n",
    "            print(dheader)\n",
    "            print(dline)\n",
    "        told = t1\n",
    "        iter_ += 1\n",
    "        SSE_old = SSE\n",
    "\n",
    "        # C (and alpha) update\n",
    "        XSt = np.dot(X[:, U], S.T)\n",
    "        #print(XSt)\n",
    "        C, SSE, muC, mualpha, CtXtXC, XC = C_update(\n",
    "            X[:, I], XSt, XC, SSt, C, delta, muC, mualpha, SST, SSE, 10\n",
    "        )\n",
    "        #print(C,SSE,muC,mualpha,CtXtXC,XC)\n",
    "\n",
    "        # S update\n",
    "        XCtX = np.dot(XC.T, X[:, U])\n",
    "        #print(XCtX)\n",
    "        S, SSE, muS, SSt = S_update(\n",
    "            S, XCtX, CtXtXC, muS, SST, SSE, 10\n",
    "        )\n",
    "        #print(S,SSE,muS,SSt)\n",
    "\n",
    "        # Evaluate and display iteration\n",
    "        dSSE = SSE_old - SSE\n",
    "        #print(dSSE)\n",
    "        t1 = dt.now()\n",
    "        if iter_ % 1 == 0:\n",
    "            time.sleep(0.000001)\n",
    "            varexpl = (SST - SSE) / SST\n",
    "            if verbose:\n",
    "                print('%10.0f | %10.4f | %10.4e | %10.4e | %10.4e | %10.4e | %10.4e | %10.4f \\n' % (iter_, varexpl, SSE, dSSE/np.abs(SSE), muC, mualpha, muS, (t1-told).seconds))\n",
    "\n",
    "    # Display final iteration\n",
    "    varexpl = (SST - SSE) / SST\n",
    "    #print(varexpl)\n",
    "    if verbose:\n",
    "        print(dline)\n",
    "        print(dline)\n",
    "        print('%10.0f | %10.4f | %10.4e | %10.4e | %10.4e | %10.4e | %10.4e | %10.4f \\n' % (iter_, varexpl, SSE, dSSE/np.abs(SSE), muC, mualpha, muS, (t1-told).seconds))\n",
    "\n",
    "    #print(S)\n",
    "    #print(C)\n",
    "    #print(XC)\n",
    "        \n",
    "    # Sort components according to importance\n",
    "    ind, vals = zip(\n",
    "        *sorted(enumerate(np.sum(S, axis=1)), key=lambda x: x[0], reverse=1)\n",
    "    )\n",
    "    S = S[ind, :]\n",
    "    C = C[:, ind]\n",
    "    XC = XC[:, ind]\n",
    "\n",
    "    return XC, S, C, SSE, varexpl\n",
    "\n",
    "XC2, S2, C2, SSE2, varexpl2 = PCHAm(dec6_wo_st, noc=3, I = None, delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_matrix_pd = pd.DataFrame(S2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec6_state = dec6_state.reset_index()\n",
    "dec6_state = dec6_state['state']\n",
    "dec6_state\n",
    "S_pd = pd.concat([dec6_state, S_matrix_pd], axis=1)\n",
    "S_pd\n",
    "#S_pd = S_pd.set_index('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_pd.to_csv('/Users/markomiholjcic/Documents/GitHub/ArchetypalAnalysis/data/SdataFrame.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec6_variables = dec6_variables.rename(columns={0: \"var\"})\n",
    "dec6_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC2_pd = pd.DataFrame(XC2)\n",
    "XC2_pd = pd.concat([dec6_variables,XC2_pd], axis = 1)\n",
    "#XC2_pd = XC2_pd.set_index(\"var\")\n",
    "XC2_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XC2_pd.to_csv('/Users/markomiholjcic/Documents/GitHub/ArchetypalAnalysis/data/XC.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XC, S, C, SSE, varexpl = PCHA(dec6_wo_st, noc=3, I = None, delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = 0\n",
    "\n",
    "a = XC[:,0] - XC2[:,1]\n",
    "ans = ans + a\n",
    "\n",
    "ans2 = 0\n",
    "\n",
    "a = XC[:,1] - XC2[:,2]\n",
    "ans2 = ans2 + a\n",
    "\n",
    "ans3 = 0\n",
    "\n",
    "a = XC[:,2] - XC2[:,0]\n",
    "ans = ans3 + a\n",
    "    \n",
    "print(ans, ans2, ans3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = 0\n",
    "\n",
    "for i in range(len(S)):\n",
    "    a = S[i] - S2[i]\n",
    "    ans = ans + a\n",
    "    \n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = 0\n",
    "\n",
    "for i in range(len(C)):\n",
    "    a = C[i] - C2[i]\n",
    "    ans = ans + a\n",
    "    \n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa=pd.read_csv(\"/Users/u0984549/Documents/GitHub/ArchetypalAnalysis/data/FIFA.csv\")\n",
    "fifa = fifa[['Name','Age', 'Overall', 'Position', 'Crossing','Finishing','HeadingAccuracy',\n",
    "            'ShortPassing','Volleys','Dribbling','Curve','FKAccuracy','LongPassing',\n",
    "            'BallControl','Acceleration','SprintSpeed','Agility','Reactions','Balance',\n",
    "            'ShotPower','Jumping','Stamina','Strength','LongShots','Aggression',\n",
    "            'Interceptions','Positioning','Vision','Penalties','Composure','Marking',\n",
    "            'StandingTackle','SlidingTackle','GKDiving','GKHandling','GKKicking',\n",
    "            'GKPositioning','GKReflexes']]\n",
    "fifa.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fifa = fifa.drop(labels=['Name', 'Position'], axis=1)\n",
    "fifa = pd.DataFrame(fifa)\n",
    "fifa = fifa.dropna()\n",
    "#fifa_num = fifa.to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa.to_csv('/Users/u0984549/Documents/GitHub/ArchetypalAnalysis/data/fifaRatings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_s = fifa.head(20)\n",
    "fifa_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa_s.to_csv('/Users/u0984549/Documents/GitHub/ArchetypalAnalysis/data/fifaRatingsSmall.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
